import numpy as np
import scipy.signal as signal
import matplotlib.pyplot as plt
from scipy.io import wavfile

TARGET_FS = 55000
FC1 = 5000
FC2 = 15000
FC3 = 25000
LC1 = 1000
HC1 = 9000
LC2 = 10000
HC2 = 18000
LC3 = 20000
HC3 = 27000


def plot_time_domain_array(audio_list, figure_name, img_index):
    output = f'../output/images/{img_index}-{figure_name}_time_domain.png'
    fig, axs = plt.subplots(len(audio_list), 1, figsize=(15, 10))
    for idx, audio in enumerate(audio_list):
        axs[idx].plot(audio)
        axs[idx].set_title(f'{figure_name} {idx + 1} - Time Domain')
        axs[idx].set_xlabel('Samples')
        axs[idx].set_ylabel('Amplitude')
        axs[idx].grid(True)
    plt.tight_layout()
    plt.savefig(output)
    plt.close()


def plot_frequency_domain_array(audio_list, figure_name, img_index):
    output = f'../output/images/{img_index}-{figure_name}_frequency_domain.png'
    fig, axs = plt.subplots(len(audio_list), 1, figsize=(15, 10))
    for idx, audio in enumerate(audio_list):
        spectrum = np.fft.fftshift(np.fft.fft(audio))
        freqs = np.fft.fftshift(np.fft.fftfreq(len(audio), 1 / TARGET_FS))
        axs[idx].plot(freqs, np.abs(spectrum))
        axs[idx].set_title(f'{figure_name} {idx + 1} - Frequency Domain')
        axs[idx].set_xlabel('Frequency (Hz)')
        axs[idx].set_ylabel('Amplitude')
        axs[idx].grid(True)
    plt.tight_layout()
    plt.savefig(output)
    plt.close()


def plot_frequency_domain(audio, figure_name, img_index):
    spectrum = np.fft.fftshift(np.fft.fft(audio))
    freqs = np.fft.fftshift(np.fft.fftfreq(len(audio), 1 / TARGET_FS))
    output = f'../output/images/{img_index}-{figure_name}_frequency_domain.png'
    plt.figure(figsize=(15, 10))
    plt.plot(freqs, np.abs(spectrum))
    plt.title(f'{figure_name} - Frequency Domain')
    plt.xlabel('Frequency (Hz)')
    plt.ylabel('Amplitude')
    plt.grid(True)
    plt.savefig(output)
    plt.close()


def low_pass_filter(audio, cutoff=4000, filter_order=50):
    lpf = signal.firwin(filter_order, cutoff, fs=TARGET_FS)
    filtered_audio = signal.lfilter(lpf, 1.0, audio)
    return filtered_audio


def band_pass_filter(audio, low_cutoff, high_cutoff, filter_order=50):
    bpf = signal.firwin(
        filter_order, [low_cutoff, high_cutoff], pass_zero=False, fs=TARGET_FS)
    return signal.lfilter(bpf, 1.0, audio)


def read_audio(filename):
    fs, audio = wavfile.read(filename)
    audio_resampled = signal.resample(audio, int(len(audio) * TARGET_FS / fs))
    return audio_resampled


def align_audio(audio_list):
    min_length = min(len(audio) for audio in audio_list)
    aligned_audio = [audio[:min_length] for audio in audio_list]
    return aligned_audio


def modulate_audio(audio, Fc):
    t = np.arange(len(audio)) / TARGET_FS
    return audio * np.cos(2 * np.pi * Fc * t)


def process_audio(Fc, input_name):
    audio = read_audio(f'../input/{input_name}.wav')
    filtered = low_pass_filter(audio)
    mod = modulate_audio(filtered, Fc)
    mod_filtered = low_pass_filter(mod, Fc, 200)  # 200 for sideband filtering
    return audio, filtered, mod, mod_filtered


def reconstruct_audio(combined_audio, low_cutoff, high_cutoff, Fc, output_name):
    bf = band_pass_filter(combined_audio, low_cutoff, high_cutoff)
    demod = modulate_audio(bf, Fc)
    final = low_pass_filter(demod)
    output_file = f'../output/voices/{output_name}.wav'
    wavfile.write(output_file, TARGET_FS, final.astype(np.int16))
    return bf, demod, final


def process():
    audio1, filtered1, mod1, mod_filtered1 = process_audio(FC1, 'input1')
    audio2, filtered2, mod2, mod_filtered2 = process_audio(FC2, 'input2')
    audio3, filtered3, mod3, mod_filtered3 = process_audio(FC3, 'input3')
    plot_time_domain_array([audio1, audio2, audio3], "Original", 1)
    plot_frequency_domain_array([audio1, audio2, audio3], "Original", 2)
    plot_frequency_domain_array([filtered1, filtered2, filtered3], 'LPF', 3)
    plot_frequency_domain_array([mod1, mod2, mod3], 'Modulation', 4)
    plot_frequency_domain_array(
        [mod_filtered1, mod_filtered2, mod_filtered3], 'Modulation_LPF', 5)
    return mod_filtered1, mod_filtered2, mod_filtered3


def combine(audio_list):
    aligned_audio = align_audio(audio_list)
    combined_audio = np.sum(aligned_audio, axis=0)
    plot_frequency_domain(combined_audio, 'Full_Spectrum', 6)
    return combined_audio


def reconstruct(combined):
    bf1, demod1, final1 = reconstruct_audio(combined, LC1, HC1, FC1, 'output1')
    bf2, demod2, final2 = reconstruct_audio(combined, LC2, HC2, FC2, 'output2')
    bf3, demod3, final3 = reconstruct_audio(combined, LC3, HC3, FC3, 'output3')
    plot_frequency_domain_array([bf1, bf2, bf3], 'BPF', 7)
    plot_frequency_domain_array([demod1, demod2, demod3], 'Demodulation', 8)
    plot_time_domain_array([final1, final2, final3], 'Final', 9)


def main():

    print("ðŸ‘‹ Welcome to the Audio Signal Processing System!")
    print("-----------------------------------")

    print("ðŸ”„ Processing Audio Signals.....")
    audio_list = process()

    print("ðŸ”„ Combining Audio Signals.....")
    combined_audio = combine(audio_list)

    print("ðŸ”„ Reconstructing Audio Signals.....")
    reconstruct(combined_audio)

    print("-----------------------------------")
    print("âœ… Done! Check the output folder for the audio files and images :)")


if __name__ == "__main__":
    main()
